\section{AreaComp V1}

Die erste Version ist eine naive Implementierung. Der Algorithmus verwaltet eine Menge von Regeln. Jede Regel besitzt eine einzigartige natürliche Zahl als ID. Der Begriff \emph{Regel} wird synonym mit dessen Regel-ID verwendet. 

In jedem Durchlauf wird nacheinander jede Regel $(X \rightarrow w) \in P$ aus der Menge entnommen und das Suffix- und LCP-Array für die rechte Seite dieser Regel berechnet. Es wird nun eine Prioritätswarteschlange erzeugt, die alle möglichen LCP-Intervalle enthält. Das beste LCP-Intervall wird daraus entnommen. Sei $p \in (N \cup \Sigma)^*$ das, durch das LCP-Intervall bestimmte, zu ersetzende Muster. Die Indizes, an denen ein Vorkommen von $p$ in $w$ existiert, kann einfach mithilfe des Suffix- und LCP-Array berechnet werden.

Es werden nun alle bestimmten Vorkommen darauf untersucht, ob sich diese mit Anderen überschneiden. Hierzu werden die Indizes, an denen $p$ vorkommt, aufsteigend sortiert und durchlaufen. Dabei werden alle Indizes gelöscht, die einen Abstand von weniger als $|p|$ zum letzten Index haben, gelöscht. Damit bleiben nur Vorkommen übrig, die sich nicht überschneiden. Sind nun nur noch weniger als zwei Positionen übrig, so wird das nächst-beste LCP-Intervall aus der Warteschlange entnommen und der Vorgang wiederholt. Sind keine Intervalle mehr übrig, so fahre zur nächsten Produktionsregel fort.

Der von diesem Intervall bestimmte Substring wird dann durch ein neues Nichtterminal und eine zugehörige Produktionsregel ersetzt. Zu diesem Zweck wird die gesamte Grammatik nach Vorkommen durchsucht und diese durch das Nichtterminal ersetzt.

Die Datenstruktur, mit der Regeln, Terminale und Nichtterminale verwaltet werden, ist gleich der Datenstruktur, die Sequitur benutzt. Allerdings verwendet der Algorithmus zusätzlich eine Hashtabelle, die eine Regel-ID auf das zugehörige Regel-Objekt abbildet.

Diese Implementierung hat nicht das Problem, dass sich Substitutionen entstehen können, die sich mit vorherigen Substitutionen überschneiden, da Suffix- und LCP-Array für jede Regel symbolweise neu erzeugt werden. 

\begin{algorithm}[t]
    \KwIn{$s:$ String}
    \KwOut{Straight-Line-Grammatik für $s$}
    \While{ Eine neue Regel kann erzeugt werden }{
        \For{Regel \texttt{rule} in der Regelmenge}{
            $SA, LCP \leftarrow$ Suffix- und LCP-Array für rechte Seite von $rule$\;
            $queue \leftarrow$ Prioritätswarteschlange aller LCP-Intervalle der rechten Seite von $rule$, geordnet mithilfe der Flächenfunktion\;
            \Do{$queue \neq \emptyset$ \And $positions.length \leq 1$}{
                $[l..r] \leftarrow queue.poll()$\;
                $positions \leftarrow$ Array der Indizes der Vorkommen des durch $[l..r]$ beschriebenen Musters (mithilfe von $SA$)\;
                $len \leftarrow \min_{i \in [l..r]} LCP[i]$\;
                Sortiere $positions$ aufsteigend\;
                Entferne überlappende Vorkommen aus $positions$\;
            }
            \If{$positions.length \leq 1$}{
                \KwBreak \;
            }
            Substituiere alle Vorkommen in $positions$ mit der Länge $len$\;
        }
    }
    \KwRet{Regelmenge}
    \caption{AreaCompV1}
    \label{v1algo}
\end{algorithm}

\subsection{Probleme}

\subsubsection{Laufzeit}
\label{v1problemruntime}

Das größte Problem dieser Implementierung ist die Laufzeit. Sei $s \in \Sigma^*$ mit $n := |s|$ der Eingabestring.

Wie in \autoref{v1algo} dargestellt, wird in jedem Durchlauf der While-Schleife jeweils durch die Menge der zu diesem Zeitpunkt existierenden Regeln iteriert. 
In jedem Durchlauf wird für jede Regel $rule := X \rightarrow w \in P, X \in N, w \in (N \cup \Sigma)^*$ das im Bezug auf die Flächenfunktion beste LCP-Intervall im LCP-Array von $w$ berechnet. Dessen Berechnung dominiert die Laufzeit dieser Version des Algorithmus. 
Es existieren $|w|^2$ solche Intervalle. Für jedes dieser LCP-Intervalle muss die Flächenfunktion berechnet werden, da diese in die Prioritätswarteschlange eingefügt werden müssen (Zeile 4). Eine Flächenfunktion, die alle Werte in ihrem gegebenen Intervall $I$ in Betracht zieht, muss mindestens eine Laufzeit von $\mathcal{O}(|I|)$ haben, da das Minimum im Intervall linear gesucht werden muss.

Im Worst-Case kann in $w$ keine Substitution mehr durchgeführt werden kann. In diesem Fall muss die Do-While-Schleife alle $|w|^2$ Intervalle verarbeiten. Jeder Durchlauf der Do-While-Schleife benötigt $\mathcal{O}(|w| \log |w|)$ Laufzeit, dominiert durch das Sortieren des $positions$ Array. Also folgt eine Worst-Case Laufzeit von $\mathcal{O}(|w|^3 \log |w|)$ für die For-Schleife. Da $|w|$ in $\mathcal{O}(n)$ liegt, resultiert eine Laufzeit von $\mathcal{O}(n^3 \log n)$ für einen Durchlauf der While-Schleife.

Da die Gesamtlänge der Grammatik $n$ nicht überschreiten kann und die Größe der Grammatik in jedem Durchlauf der While-Schleife um mindestens $1$ sinken muss, können im Worst-Case $\mathcal{O}(n)$ Iterationen der While-Schleife stattfinden. Insgesamt folgt im Worst-Case also eine Laufzeit von $\mathcal{O}(n^4 \log n)$.


\subsubsection{Erkennung von Wiederholungen}

Diese Version des Algorithmus erkennt keine wiederholten Vorkommen von Substrings, falls diese in verschiedenen Produktionsregeln auftreten.
Etwa würde in der folgenden Grammatik das wiederholte Vorkommen von $abc$ nicht erkannt werden:

\begin{align*}
	S &\rightarrow AA\textcolor{red}{abc}\\
	A &\rightarrow cdef\textcolor{red}{abc}
\end{align*}

Dies liegt daran, dass das Suffix- und LCP-Array, in dem nach wiederholten Vorkommen gesucht wird, für jede Produktionsregel einzeln berechnet werden. Dabei werden natürlich alle Vorkommen außerhalb dieser Produktionsregel nicht erfasst.