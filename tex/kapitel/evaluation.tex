% IMPORT-DATA dna dna.txt
% IMPORT-DATA proteins proteins.txt
% IMPORT-DATA xml dblp.xml.txt
% IMPORT-DATA english english.txt

\pgfplotscreateplotcyclelist{algs}{%
    lime!80!black,every mark/.append style={fill=lime},mark=square*\\%
    red,every mark/.append style={fill=red},mark=triangle*\\%
    teal,every mark/.append style={fill=teal!80},mark=pentagon*\\%
    black,mark=star\\%
    purple!30!blue,every mark/.append style={fill=purple!30!blue},mark=diamond*\\%
    orange!80!black,every mark/.append style={solid,fill=orange},mark=*\\%
}

\pgfplotsset{
    dataplot/.style={
        xtick={1,2,3,4,5},
        xticklabels={10,20,30,40,50},
        xticklabel style={align=center},
        xlabel={Größe der Eingabe},
        x unit={MB},
        width=70mm,
        height=6cm,,
        legend style={at={(1.1,0.5)}, anchor=west},
        cycle list name=algs
    },
    runtimeplot/.style={
        dataplot,
        y unit={s},
        ylabel={Laufzeit},
        ytick distance=50
    },
    sizeplot/.style={
        dataplot,
        %y unit={outputsize/inputsize},
        ylabel={Größenverhältnis},
        ytick distance=0.1
    },
    depthplot/.style={
        dataplot,
        %y unit={\#Schritte zur tiefsten Regel},
        ylabel={Tiefe}
    },
    countplot/.style={
        dataplot,
        ylabel={Regeln}
    },
    lengthplot/.style={
        dataplot,
        %y unit={\#Zeichen},
        ylabel={Durchschnittslänge}
    },
}

\chapter{Evaluation}

\section{Methodik}

Bei der Evaluation der Algorithmen werden Sequitur (siehe \autoref{sequitur}), RePair (siehe \autoref{repair}) und AreaComp V4 (siehe \autoref{v4}) mit verschiedenen Flächenfunktionen auf verschiedene Datensätze angewendet.

Die Algorithmen werden auf einem Windows 10 Gerät ausgeführt mit einem AMD Ryzen 5 2600X Prozessor (6 physische Kerne bei 3.6GHz) und 16GB RAM.

\subsection{Implementationen}

Die hier gewählte Implementation von Sequitur ist die Java-Implementation von Eibe Frank\footnote{\url{http://www.sequitur.info/java}}. 

Für RePair wird eine eigene Implementation benutzt. Die meisten bestehenden Implementationen waren in nicht JVM-kompatiblen Programmiersprachen geschrieben. 
Die einzige auffindbare JVM-kompatible Implementation war eine Kotlin-Implementierung von Dale King \footnote{\url{https://gitlab.com/NobleworksSoftware/RePair}}. Allerdings ist diese für größere Grammatiken nicht verwendbar, da sie UTF-16 Codepoints als Nichtterminale verwendet. Da Diese auf Zahlen unter $2^16$ begrenzt sind, ist diese Implementation nicht auf die hier verwendeten Testdaten anwendbar, weil die auf den hier verwendeten Datensätzen erzeugten Grammatiken größer sind.

Die Implementation von AreaCompV4 sowie die Sequitur- und RePair-Implementation sind in Java 16 programmiert.

\subsection{Datensätze}

Die hier gewählten Datensätzen stammen aus dem Pizza\&Chili Corpus\footnote{\url{http://pizzachili.dcc.uchile.cl}}. Die Algorithmen werden jeweils auf $10$, $20$, $30$, $40$ und $50$MB Präfixe folgender Datensätze angewendet:

\begin{itemize}[leftmargin=2cm]
    \item[\emph{dna}] DNA Sequenzen von Project Gutenberg\footnote{\label{footnotegutenberg}\url{https://www.gutenberg.org}}. Jedes Basenpaar wird jeweils durch einen der Großbuchstaben \emph{A}, \emph{G}, \emph{C} und \emph{T} dargestellt. Zudem kommen einige Sonderzeichen vor. Das Alphabet besteht aus 16 Zeichen.
    \item[\emph{english}] Englischer Text von Project Gutenberg\footnoteref{footnotegutenberg}. Das Alphabet besteht aus 239 Zeichen.
    \item[\emph{proteins}] Proteinsequenzen aus der Swissprot Datenbank\footnote{\url{ftp://ftp.ebi.ac.uk/pub/databases/swissprot/release_compressed/uniprot_sprot.dat.gz}}. Jede Aminosäure ist mit jeweils einem Buchstaben kodiert. Das Alphabet besteht aus 27 Zeichen.
    \item[\emph{xml}] Eine XML-Datei mit Informationen über große Informatik-Zeitschriften etc. von der Universität Trier\footnote{\url{https://dblp.uni-trier.de}}. Das Alphabet besteht aus 97 Zeichen.
\end{itemize}

\subsection{Flächenfunktion}

Wir betrachten vier Flächenfunktionen. Diese machen sich die Eigenschaften der \\
Abouelhoda-Intervalle zunutze. 
Wie in \cite{abouelhoda_optimal_2002} beschrieben, lässt sich der minimale LCP-Wert eines Abouelhoda-Intervalls $[i..j]$ durch $down[i]$ oder $up[j+1]$ im Kind-Array bestimmen. 
So muss nicht in Linearzeit durch das Intervall iteriert werden, um das Minimum zu bestimmen. Es kann stattdessen durch eine Konstantzeit-Anfrage an das Kind-Array bestimmt werden. 

Da AreaComp V1 und V2 beliebige LCP-Intervalle verwenden, funktioniert dieses Vorgehen für diese Versionen von AreaComp nicht. Dieses Vorgehen ist also erst ab V3 möglich, da erst ab V3 ausschießlich Abouelhoda-Intervalle benutzt werden.

Für alle folgenden Flächenfunktionen gilt, dass wenn $H(i+1, j) \leq 1$ gilt(siehe \autoref{areacompconcept} für die Definition von $H$ und $W$), als resultierender Flächenwert automatisch $0$ zurückgegeben wird. Da LCP-Intervalle mit Höhe $\leq 1$ einen Substring einer Länge von maximal $1$ beschreiben, sind diese für unsere Zwecke unnütz.  

Im Folgenden sei $I := [i..j]$ ein Abouelhoda-Intervall. Dann ist $LCP[i+1..j]$ das zugehörige LCP-Intervall und seien $h := H(i+1, j)$ und $w := W(i+1, j)$. Wir definieren folgende Flächenfunktionen:

\begin{itemize}[leftmargin=3.6cm]
    \item[\texttt{ChildArea}] $A(I) = h \cdot w$\\
    Diese Flächenfunktion schätzt die erreichbare Kompression durch eine Multiplikation der Anzahl der Vorkommen ($w$) mit der Länge des ersetzten Substrings ($h$) ab.
    \item[\texttt{WidthFirstArea}] $A(I) = w$\\ Hier wird allein die Anzahl der Vorkommen Priorisiert.
    \item[\texttt{HeightFirstArea}] $A(I) = h$\\
    Hier wird allein die Länge des zu ersetzenden Substrings priorisiert.
    \item[\texttt{HeightAdvantageArea}] $A(I) = 10 \cdot h + \min\{\ln(w), 9\}$\\ 
    Diese Flächenfunktion ist der Versuch einer Verbesserung von \\
    \texttt{HeightFirstArea}. Da bei \texttt{HeightFirstArea} allein die Höhe des LCP-Intervalls berücksichtigt wird, ist es möglich, dass LCP-Intervalle vor anderen LCP-Intervallen mit gleicher Höhe aber größerer Breite gewählt werden. Allerdings sind aber Letztere a priori vielversprechender. Die Höhe wird mit dem Faktor $10$ multipliziert. Der Unterschied in der Höhe von LCP-Intervallen geht also zehnfach in die Flächenfunktion ein. So entsteht zwischen zwei LCP-Intervallen, die sich um $1$ in der Höhe unterscheiden, ein Unterschied von $10$. Innerhalb des entstehenden Intervalls können also weitere Unterscheidungen stattfinden. 

    Hier ist das Ziel, dass möglichst unter den Intervallen mit gleicher Höhe, Intervalle mit größerer Breite vor Intervallen mit niedrigerer Breite gewählt werden sollen. \texttt{HeightFirstArea} lässt dies außer Acht, daher ist die Reihenfolge der Intervalle gleicher Höhe willkürlich.

    Die Lösung ist also  logarithmisch die Breite in die Berechnung miteinzubringen und diesen Wert auf maximal $9$ zu begrenzen. Dies sorgt dafür, dass die Breite des Intervalls ebenfalls in den Flächenwert miteingeht. Zudem wird aber gesichert, dass nie ein bestimmtes Intervall über ein anderes Intervall mit größerer Höhe priorisiert werden kann. 
    
    Für diese Flächenfunktion können anstatt $10$ und $9$ im Grunde beliebige Zahlen $k$ und $k - 1$ für $k \geq 2$ gewählt werden. Ebenfalls kann der Algorithmus zu einer beliebigen Basis gewählt werden.
    Abhängig von $k$ kann die Flächenfunktion dann entscheiden, in welchen der $k$ durch den Logarithmus gegebenen Bereichen $w$ liegt. Ist $b$ die Basis des Logarithmus, sind diese Bereiche sind jeweils $[1..b^1), [b^1..b^2), \dots [b^{k-1}..\infty)$. 

    In der Implementierung von AreaComp wird hierzu der natürliche Logarithmus und $k = 10$ gewählt.
    So ist die Grenze, bis zu der die Flächenfunktion Breitenwerte unterscheiden kann, $e^9 \approx 8103$. Da es nicht anzunehmen ist, dass es sehr viele größere Muster gibt, die öfter als $e^9$-Mal vorkommen, ist dies eine angemessene Wahl für diese Datensätze.
\end{itemize}

\section{Ergebnisse}
\label{results}

%%%%%%
\autoref{resultsdna} bis \ref{resultsenglish} zeigen die Ergebnisse der Algorithmen auf den verschiedenen Datensätzen. 

In den Abbildungen $a)$ sehen wir die Laufzeit der Algorithmen in Sekunden für die Präfixe der angegebenen Größe in MB.

Die Abbildungen $b)$ zeigen die Größenverhältnisse der Größe der von den Algorithmen produzierten Grammatik zu der Länge der Eingabe. Die Größe ist dabei wie in \autoref{grammarcomp} definiert. Für eine Grammatik $G :=(N, \Sigma, P, S)$ ist die Größe $|G|$ also definiert als
\begin{equation*}
	|G| := \sum_{(A \rightarrow \alpha) \in P} |\alpha|.
\end{equation*}
Für eine Eingabe $s$ der Länge $n$ und der von einem Algorithmus erzeugten Grammatik $G_s$, ist in den Abbildungen also $\tfrac{|G_s|}{n}$ aufgeführt.

Abbildungen $c)$ zeigen dabei die Tiefe der erzeugten Grammatiken. Die Tiefe ist dabei folgendermaßen definiert: Betrachte den Syntaxbaum einer Ableitung einer Grammatik, wie in \autoref{syntaxtree} dargestellt. Da wir hier Straight-Line-Grammatiken betrachten, ist der Syntaxbaum jeder Grammatik einzigartig. Die Tiefe der Grammatik ist definiert als die Tiefe des Syntaxbaums, also die Anzahl der Kanten, die von der Wurzel zum am weitesten entfernten Knoten führen.  

\begin{figure}
    \centering
    \subfloat[Grammatik]{
        \parbox[t][3cm][c]{5cm}{
            \centering
            $\begin{aligned}
                S &\rightarrow AB\\
                A &\rightarrow ab\\
                B &\rightarrow cC\\
                C &\rightarrow de
            \end{aligned}$
        }
    }
    \subfloat[Syntaxbaum]{
        \parbox[t][3cm][c]{5cm}{
            \centering
            \begin{tikzpicture}
                \node (S) at (0,0) {S};
                \node (A) at (-1, -1) {A};
                \node (ab) at (-1, -2) {ab};
                \node (B) at (1, -1) {B};
                \node (c) at (0, -2) {c};
                \node (C) at (2, -2) {C};
                \node (de) at (2, -3) {de};

                \draw (S) -- (A);
                \draw (S) -- (B);
                \draw (A) -- (ab);
                \draw (B) -- (c);
                \draw (B) -- (C);
                \draw (C) -- (de);
            \end{tikzpicture}
        }
    }
    \caption{Eine Grammatik und der zugehörige Syntaxbaum für den String $abcde$.}
    \label{syntaxtree}
\end{figure}

Abbildungen $d)$ zeigen die Anzahl von Produktionsregeln in den Grammatiken. 

Zuletzt, zeigen die Abbildungen $e)$ die durchschnittliche Länge der rechten Seite der Regeln in der Grammatik.

\subsection{Laufzeit}

Auf allen Datensätzen ist Sequitur der schnellste Algorithmus. Wie in \autoref{resultsenglishruntime} zu sehen ist, hat Sequitur auf dem \emph{english} Datensatz einen besonders großen Abstand zu den anderen Algorithmen. Der nächstschnellste Algorithmus ist hier RePair, der auf dem \emph{english} Datensatz etwa $4,3$-Mal so viel Zeit benötigt wie Sequitur. Auf anderen Datensätzen ist der Abstand allerdings geringer.
Im Vergleich zu Sequitur und Repair erzielte AreaComp weitaus schlechtere Laufzeiten.

Die Wahl der Flächenfunktion schien in manchen Fällen keine große Auswirkung auf die Laufzeit zu haben. In \autoref{resultsproteinsruntime} und \autoref{resultsxmlruntime} sehen wir, dass es auf den Datensätzen \emph{proteins} und \emph{xml} nur einen sehr kleinen Unterschied zwischen den Flächenfunktionen gibt. 
Jedoch war AreaComp auf dem \emph{dna} Datensatz mit den Flächenfunktionen \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea} etwa $24$\% langsamer als mit \texttt{ChildArea} und \texttt{WidthFirstArea}. Auf dem \emph{english} Datensatz hingengen schien nur \texttt{WidthFirstArea} schneller zu sein als die anderen Flächenfunktionen. Hier waren diese etwa $28$\% langsamer als \texttt{WidthFirstArea}und damit nur $17$\% langsamer als RePair, wie in \autoref{resultsenglishruntime} zu sehen ist.

Ebenfalls ist zu beobachten, dass die Laufzeit von AreaComp linear zu steigen scheint.

\subsection{Grammatikgröße}
\label{grammarsize}

Auf diesen Datensätzen RePair produzierte RePair die größten und tiefsten Grammatiken. Eine Ausnahme ist der \emph{xml} Datensatz. Wie in \autoref{resultsxmlsize} zu sehen, produzierte AreaComp mit der \texttt{WidthFirstArea} eine größere Grammatik als RePair.

Der Grund für die Größe der von RePair produzierten Grammatiken ist wahrscheinlich, dass RePair nur Produktionsregeln der Länge $2$ besitzt, die Startregel ausgeschlossen. Da viele solcher Regeln rekursiv erstellt werden, ist die Grammatik auch sehr tief. Allerdings können diese Eigenschaften möglicherweise Vorteile bei der Kodierung liefern. \cite{tabei_succinct_2013}

Abgesehen von der zuvor erwähnten Ausnahmen, produziert AreaComp mit der\\
\texttt{WidthFirstArea} die nächstkleinere Grammatik. AreaComp mit \texttt{ChildArea} produziert wiederum die nächstkleinere Grammatik. Allerdings variiert der Unterschied zwischen diesen beiden auf den verschiedenen Datensätzen. Während auf dem \emph{xml} \texttt{WidthFirstArea} eine $120$\% größere Grammatik produziert als \texttt{ChildArea} (siehe \autoref{resultsxmlsize}), ist die Größe auf dem \emph{dna} Datensatz fast identisch (siehe \autoref{resultsdnasize}).

Weitaus bessere Ergebnisse erzielt AreaComp mit den Flächenfunktionen \\
\texttt{HeightFirstArea} und \texttt{HeightAdvantageArea}.
Diese produzierten fast gleich große Grammatiken auf jedem Datensatz. \texttt{ChildArea} produziert auf \emph{dna}, \emph{xml} und \emph{english} eine etwa $120$\% größere Grammatik als \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea} (siehe jeweils \autoref{resultsdnasize}, \autoref{resultsxmlsize} und \autoref{resultsenglishsize}). Auf \emph{proteins} ist der Unterschied allerdings nur etwa $53$\% (siehe \autoref{resultsproteinssize}).

Auf jedem Datensatz produzierte Sequitur die kleinste Grammatik. Auf \emph{xml} und \emph{english} ist der produziert AreaComp mit \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea} Grammatiken, die nur jeweils $11$\% und $16$\% größer sind, als die von Sequitur (siehe \autoref{resultsxmlsize} und \autoref{resultsenglishsize}).
Auf \emph{dna} und \emph{proteins} ist der Unterschied mit jeweils $44$\% und $26$\% etwas größer.

Insgesamt ist zu beobachten, dass nach Sequitur AreaComp mit \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea} die kleinsten Grammatiken erzeugen. Das Verhältnis von Eingabelänge zur Größe der Ausgabegrammatik bei diesen Flächenfunktionen sich nur wenig ändert. Nur auf dem \emph{proteins} Datensatz stieg dieses Verhältnis etwas, von $0.21$ auf $0.26$, wie in \autoref{resultsproteinssize} zu sehen ist. Dies lässt darauf schließen, dass die erzeugte Grammatik im Regelfall linear mit der Eingabelänge wächst.

\subsection{Grammatiktiefe}

Die von \texttt{WidthFirstArea} produzierten Grammatiken sind die flachsten Grammatiken. Nur auf dem \emph{english} Datensatz erreichte die Tiefe dieser Grammatiken eine Tiefe von $11$ (siehe \autoref{resultsenglishdepth}) Auf allen anderen Datensätzen haben diese Grammatiken nur eine Tiefe von kleiner als $10$.

Abhängig vom betrachteten Datensatz produzieren Sequitur oder AreaComp mit \\
\texttt{ChildArea} die nächst-tieferen Grammatiken. 

Die nächst-tieferen Grammatiken sind die von AreaComp mit 
\texttt{HeightFirstArea} und \texttt{HeightAdvantageArea} erzeugten Grammatiken. Für alle Datensätze liegen diese etwa im Bereich von $40$ bis $70$ und steigen nur leicht mit zunehmender Größe.
Auf dem \emph{dna} Datensatz sind diese Grammatiken mit einer Tiefe von $49$ bis $58$ deutlich tiefer als die von \texttt{ChildArea} und Sequitur produzierten Grammatiken, die hier im Bereich $7$ bis $12$ liegen, wie in \autoref{resultsdnadepth} zu sehen ist.

Auf \emph{proteins} hingegen sind die Unterschiede am kleinsten.\\
Die Grammatiken von \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea} liegen im Bereich $50$ bis $64$, die Grammatiken von \texttt{ChildArea} im Bereich $36$ bis $50$. Die Grammatiken mit einer Tiefe im Bereich $20$ bis $24$ noch etwas flacher (siehe \autoref{resultsproteinsdepth}). 

Die von RePair produzierten Grammatiken sind bei Weitem die tiefsten Grammatiken, wie schon in \autoref{grammarsize} beschrieben. Während die Grammatiken von \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea} auf keinem der Datensätze die Tiefe $100$ erreichen, so überschreiten die Grammatiken von RePair auf \emph{dna} und \emph{proteins} eine Tiefe von $1000$ (siehe \autoref{resultsdnadepth} und \autoref{resultsproteinsdepth}) und erreichen auf dem $50$MB Präfix von \emph{english} sogar eine Tiefe von über $13000$, wie wir in \autoref{resultsenglishdepth} sehen.

\subsection{Regelanzahl}

Die Grammatiken mit der niedrigsten Anzahl von Regeln werden von AreaComp mit den Flächenfunktionen \texttt{ChildArea} und \texttt{WidthFirstArea} produziert. Dabei produziert \texttt{ChildArea} etwas größere Grammatiken als \texttt{WidthFirstArea}. Die Regelanzahl der von \texttt{ChildArea} produzierten Grammatik ist für \emph{dna} nur etwa $5$\% größer als die von \texttt{WidthFirstArea} (siehe \autoref{resultsdnarulenum}). 
Der größte Unterschied ist hier im \emph{proteins} Datensatz zu finden mit einer $49$\% höheren Regelanzahl in der von \texttt{ChildArea} produzierten Grammatik. 

Der Abstand zu Sequitur, der die Grammatiken mit der nächst-größeren Anzahl an Regeln produziert, ist dabei vergleichsweise sehr groß. Die von Sequitur produzierten Grammatiken für \emph{proteins}, \emph{xml}und \emph{english} besitzen dabei jeweils $72$, $11$ und $21$-mal so viele Regeln, wie die entsprechende Grammatik von \texttt{ChildArea}, wie in den Abbildungen \autoref{resultsproteinsrulenum}, \autoref{resultsxmlrulenum} und \autoref{resultsenglishrulenum} zu sehen ist.
Der mit Abstand größte Unterschied ist in den Grammatiken des \emph{dna} Datensatz zu finden. Hier hat Sequiturs Grammatik $2686$-mal so viele Regeln wie die Grammatik von \texttt{ChildArea}. 

Der Algorithmus der die Grammatik mit der nächst-größeren Regelanzahl produziert ist abhängig von dem betrachteten Datensatz. 

Die von \texttt{HeightFirstArea}, \texttt{HeightAdvantageArea} und RePair erzeugten Grammatiken haben für den \emph{xml} Datensatz zu einander eine sehr ähnliche Anzahl an Regeln, wie in \autoref{resultsxmlrulenum} zu sehen ist. Diese Grammatiken bestehen aus etwa $38$\% mehr Regeln als die Grammatik von Sequitur.

Im \emph{dna} Datensatz ist die Grammatik mit der nächst-größeren Regelanzahl die von RePair erzeugte Grammatik. Diese ist besteht aus etwa $32$\% mehr Regeln. In etwas größerem Abstand liegen die Grammatiken von \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea}. Diese enthalten etwa $4.9$-mal so viele Regeln wie die Grammatik von Sequitur (siehe \autoref{resultsdnarulenum}).

In \autoref{resultsproteinsrulenum} sehen wir, dass die Regelanzahl der RePair Grammatik auf dem \emph{proteins} Datensatz von $30$MB auf $40$MB sogar sinkt. Bis einschließlich $30$MB enthält die RePair Grammatik etwa $50$\% mehr Regeln als die von \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea}. Ab $40$MB sinkt die Anzahl der Regeln in der RePair Grammatik unter die Anzahl der Grammatiken von \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea}.

Auf dem \emph{english} Datensatz produzierten \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea} Grammatiken mit etwa doppelt so vielen Regeln wie die von Sequitur.
RePair produziert hier mit Abstand die Grammatik mit den meisten Regeln. Die RePair Grammatik enthät etwa $4.2$-mal so viele Regeln wie die von \texttt{HeightFirstArea} und \texttt{HeightAdvantageArea}.

\subsection{Durchschnittliche Regellänge}

Bei der durchschnittlichen Regellänge lohnt es nicht RePair zu betrachten, da RePair für jede Regel, außer der Startregel eine Länge von $2$ vorschreibt.

Wie in \autoref{resultsdnaavglen} und \autoref{resultsxmlavglen} zu sehen, ist für alle Algorithmen die Durchschnittslänge auf den Datensätzen \emph{dna} und \emph{xml} zwischen $2$ und $3$, im Fall von \emph{dna} sogar zwischen $2$ und $2.2$. Allerdings gibt es trotzdem Unterschiede. Auf dem \emph{dna} Datensatz produzierte AreaComp mit \texttt{HeightFirstArea} die Grammatik mit der höchsten durchschnittlichen Regellänge, während AreaComp mit \texttt{WidthFirstArea} die niedrigste Regellänge liefert.

Auf \emph{xml} hingegen, produziert \texttt{HeightFirstArea} die Grammatik mit den kürzesten Regeln und \texttt{WidthFirstArea} die mit den längsten Regeln.

Auf \emph{proteins} und \emph{english} produziert \texttt{ChildArea} Grammatiken mit durchschnittlichen Regellängen von über $10$ (siehe \autoref{resultsproteinsavglen}). Auf dem \emph{english} Datensatz sogar bis zu $96$.
Hier produziert auch \texttt{WidthFirstArea} eine Grammatik mit einer durchschnittlichen Regellänge von bis zu $40$ (siehe \autoref{resultsenglishavglen}).



% DNA PLOT
\begin{figure}
    \centering

    \subfloat[Laufzeiten]{
        \begin{tikzpicture}
            \begin{axis}[runtimeplot, title={DNA Laufzeit}]
               
                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG((comptime + unifytime) / 1000) AS y, MULTIPLOT
                %% FROM dna GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,47.0) (2,106.0) (3,171.0) (4,232.0) (5,314.0) };
                \addlegendentry{AreaCompV4/ChildArea};
                \addplot coordinates { (1,51.0) (2,116.0) (3,198.0) (4,282.0) (5,380.0) };
                \addlegendentry{AreaCompV4/HeightAdvantageArea};
                \addplot coordinates { (1,50.0) (2,117.0) (3,190.0) (4,266.0) (5,368.0) };
                \addlegendentry{AreaCompV4/HeightFirstArea};
                \addplot coordinates { (1,44.0) (2,103.0) (3,159.0) (4,227.0) (5,306.0) };
                \addlegendentry{AreaCompV4/WidthFirstArea};
                \addplot coordinates { (1,15.0) (2,35.0) (3,57.0) (4,75.0) (5,102.0) };
                \addlegendentry{RePair};
                \addplot coordinates { (1,4.0) (2,9.0) (3,15.0) (4,23.0) (5,31.0) };
                \addlegendentry{Sequitur};
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsdnaruntime}
    }
    \quad
    \subfloat[Größe der erzeugten Grammatik]{
        \begin{tikzpicture}
            \begin{axis}[sizeplot, title={DNA Grammatikgröße}]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, MIN(size / (1.0 * inputsize)) AS y, MULTIPLOT 
                %% FROM dna GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,0.429266) (2,0.429114) (3,0.429129) (4,0.429873) (5,0.429092) };
                
                \addplot coordinates { (1,0.216447) (2,0.205636) (3,0.201329) (4,0.197742) (5,0.194624) };
                
                \addplot coordinates { (1,0.218332) (2,0.207557) (3,0.203194) (4,0.199581) (5,0.19631) };
                
                \addplot coordinates { (1,0.429441) (2,0.429373) (3,0.429393) (4,0.430037) (5,0.429272) };
                
                \addplot coordinates { (1,0.647652) (2,0.527011) (3,0.640813) (4,0.53727) (5,0.516707) };
                
                \addplot coordinates { (1,0.146958) (2,0.139801) (3,0.138794) (4,0.137584) (5,0.135546) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsdnasize}
    }
    \ 
    \subfloat[Tiefe der erzeugten Grammatik]{
        \begin{tikzpicture}
            \begin{axis}[depthplot, title={DNA Grammatiktiefe}, ymode=log]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(depth) AS y, MULTIPLOT 
                %% FROM dna GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,7.0) (2,7.0) (3,9.0) (4,9.0) (5,9.0) };
                
                \addplot coordinates { (1,48.0) (2,52.0) (3,58.0) (4,58.0) (5,58.0) };
                
                \addplot coordinates { (1,49.0) (2,51.0) (3,57.0) (4,58.0) (5,57.0) };
                
                \addplot coordinates { (1,3.0) (2,3.0) (3,3.0) (4,3.0) (5,3.0) };
                
                \addplot coordinates { (1,335.0) (2,532.0) (3,2403.0) (4,1635.0) (5,3034.0) };
                
                \addplot coordinates { (1,11.0) (2,11.0) (3,12.0) (4,12.0) (5,12.0) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsdnadepth}
    }
    \ 
    \subfloat[Anzahl der Regeln]{
        \begin{tikzpicture}
            \begin{axis}[countplot, title={DNA Regelanzahl}, ymode=log]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(numRules) AS y, MULTIPLOT 
                %% FROM dna GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,71.0) (2,78.0) (3,154.0) (4,155.0) (5,187.0) };
                
                \addplot coordinates { (1,545201.0) (2,1.0341e+06) (3,1.51782e+06) (4,1.98592e+06) (5,2.44195e+06) };
                
                \addplot coordinates { (1,551990.0) (2,1.04767e+06) (3,1.53673e+06) (4,2.01088e+06) (5,2.47137e+06) };
                
                \addplot coordinates { (1,63.0) (2,69.0) (3,148.0) (4,148.0) (5,178.0) };
                
                \addplot coordinates { (1,113457.0) (2,319827.0) (3,303421.0) (4,619826.0) (5,666054.0) };
                
                \addplot coordinates { (1,119842.0) (2,213943.0) (3,311928.0) (4,409847.0) (5,502206.0) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsdnarulenum}
    }
    \subfloat[Durchschnittslänge der Regeln]{
        \begin{tikzpicture}
            \begin{axis}[lengthplot, title={DNA Regellänge}, ymode=log]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(avgLen) AS y, MULTIPLOT 
                %% FROM dna GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,2.01429) (2,2.02597) (3,2.02614) (4,2.01299) (5,2.04301) };
                
                \addplot coordinates { (1,2.17989) (2,2.18967) (3,2.18764) (4,2.19015) (5,2.19205) };
                
                \addplot coordinates { (1,2.19303) (2,2.20367) (3,2.20288) (4,2.20553) (5,2.20552) };
                
                \addplot coordinates { (1,2.0) (2,2.0) (3,2.01361) (4,2.0) (5,2.0339) };
                
                \addplot coordinates { (1,2.0) (2,2.0) (3,2.0) (4,2.0) (5,2.0) };
                
                \addplot coordinates { (1,2.04732) (2,2.07584) (3,2.08106) (4,2.08939) (5,2.09551) };
            \end{axis}
        \end{tikzpicture}
        \label{resultsdnaavglen}
    }
    \caption{Die Ergebnisse für die Kompression des \emph{dna} Datensatzes aus dem Pizza\&Chili Corpus. Siehe \autoref{results} für weitere Erläuterungen.}
    \label{resultsdna}
\end{figure}


% PROTEINS PLOT
\begin{figure}
    \centering

    \subfloat[Laufzeiten]{
        \begin{tikzpicture}
            \begin{axis}[runtimeplot, title={Proteins Laufzeit}]
                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG((comptime + unifytime) / 1000) AS y, MULTIPLOT
                %% FROM proteins GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,43.0) (2,97.0) (3,135.0) (4,167.0) (5,214.0) };
                \addlegendentry{AreaCompV4/ChildArea};
                \addplot coordinates { (1,40.0) (2,87.0) (3,125.0) (4,159.0) (5,202.0) };
                \addlegendentry{AreaCompV4/HeightAdvantageArea};
                \addplot coordinates { (1,39.0) (2,86.0) (3,131.0) (4,161.0) (5,205.0) };
                \addlegendentry{AreaCompV4/HeightFirstArea};
                \addplot coordinates { (1,39.0) (2,84.0) (3,118.0) (4,154.0) (5,192.0) };
                \addlegendentry{AreaCompV4/WidthFirstArea};
                \addplot coordinates { (1,16.0) (2,42.0) (3,79.0) (4,92.0) (5,123.0) };
                \addlegendentry{RePair};
                \addplot coordinates { (1,6.0) (2,15.5) (3,27.0) (4,40.0) (5,58.0) };
                \addlegendentry{Sequitur};

            \end{axis}
        \end{tikzpicture}
        \label{resultsproteinsruntime}
    }
    
    \quad
    \subfloat[Größe der erzeugten Grammatik]{
        \begin{tikzpicture}
            \begin{axis}[sizeplot, title={Proteins Grammatikgröße}]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, MIN(size / (1.0 * inputsize)) AS y, MULTIPLOT 
                %% FROM proteins GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,0.341726) (2,0.365969) (3,0.386289) (4,0.400567) (5,0.404739) };
                
                \addplot coordinates { (1,0.212851) (2,0.202009) (3,0.222857) (4,0.249495) (5,0.264087) };
                
                \addplot coordinates { (1,0.21661) (2,0.20566) (3,0.227152) (4,0.254638) (5,0.269725) };
                
                \addplot coordinates { (1,0.433566) (2,0.432746) (3,0.432112) (4,0.43228) (5,0.432293) };
                
                \addplot coordinates { (1,0.767845) (2,0.776813) (3,0.744482) (4,0.834881) (5,0.828773) };
                
                \addplot coordinates { (1,0.179865) (2,0.169194) (3,0.180369) (4,0.198115) (5,0.208265) };
                

            \end{axis}
        \end{tikzpicture}
        \label{resultsproteinssize}
    }
    \ 
    \subfloat[Tiefe der erzeugten Grammatik]{
        \begin{tikzpicture}
            \begin{axis}[depthplot, title={Proteins Grammatiktiefe}, ymode=log]
                
                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(depth) AS y, MULTIPLOT 
                %% FROM proteins GROUP BY MULTIPLOT, datasetsize      
                \addplot coordinates { (1,36.0) (2,43.0) (3,47.0) (4,49.0) (5,50.0) };
                
                \addplot coordinates { (1,53.0) (2,59.0) (3,62.0) (4,64.0) (5,64.0) };
                
                \addplot coordinates { (1,50.0) (2,52.0) (3,62.0) (4,64.0) (5,64.0) };
                
                \addplot coordinates { (1,3.0) (2,4.0) (3,4.0) (4,4.0) (5,4.0) };
                
                \addplot coordinates { (1,1628.0) (2,2819.0) (3,3413.0) (4,2982.0) (5,3733.0) };
                
                \addplot coordinates { (1,20.0) (2,24.0) (3,24.0) (4,24.0) (5,24.0) };
                
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsproteinsdepth}
    }
    \ 
    \subfloat[Anzahl der Regeln]{
        \begin{tikzpicture}
            \begin{axis}[countplot, title={Proteins Regelanzahl}, ymode=log]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(numRules) AS y, MULTIPLOT 
                %% FROM proteins GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,8497.0) (2,8319.0) (3,8036.0) (4,7568.0) (5,10243.0) };
                
                \addplot coordinates { (1,462337.0) (2,876976.0) (3,1.43681e+06) (4,2.1312e+06) (5,2.80116e+06) };
                
                \addplot coordinates { (1,481653.0) (2,913402.0) (3,1.50013e+06) (4,2.23379e+06) (5,2.9401e+06) };
                
                \addplot coordinates { (1,4890.0) (2,4931.0) (3,5214.0) (4,5242.0) (5,6884.0) };
                
                \addplot coordinates { (1,593074.0) (2,1.3128e+06) (3,2.1662e+06) (4,1.81616e+06) (5,2.02654e+06) };
                
                \addplot coordinates { (1,219631.0) (2,377264.0) (3,501559.0) (4,624574.0) (5,746617.0) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsproteinsrulenum}
    }
    \subfloat[Durchschnittslänge der Regeln]{
        \begin{tikzpicture}
            \begin{axis}[lengthplot, title={Proteins Regellänge}, ymode=log]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(avgLen) AS y, MULTIPLOT 
                %% FROM proteins GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,13.4101) (2,15.4264) (3,21.9736) (4,21.8799) (5,22.0033) };
                
                \addplot coordinates { (1,2.53079) (2,2.67598) (3,2.56286) (4,2.41029) (5,2.35682) };
                
                \addplot coordinates { (1,2.52303) (2,2.66375) (3,2.55465) (4,2.40679) (5,2.35552) };
                
                \addplot coordinates { (1,2.11004) (2,2.12049) (3,3.79762) (4,3.95669) (5,2.39271) };
                
                \addplot coordinates { (1,2.0) (2,2.0) (3,2.0) (4,2.0) (5,2.0) };
                
                \addplot coordinates { (1,2.96105) (2,3.44833) (3,3.52837) (4,3.27092) (5,3.17545) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsproteinsavglen}
    }
    \caption{Die Ergebnisse für die Kompression des \emph{proteins} Datensatzes aus dem Pizza\&Chili Corpus. Siehe \autoref{results} für weitere Erläuterungen.}
    \label{resultsproteins}
\end{figure}

% XML PLOT
\begin{figure}
    \centering

    \subfloat[Laufzeiten]{
        \begin{tikzpicture}
            \begin{axis}[runtimeplot, title={XML Laufzeit}]
                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG((comptime + unifytime) / 1000) AS y, MULTIPLOT
                %% FROM xml GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,41.0) (2,91.0) (3,145.0) (4,203.0) (5,269.0) };
                \addlegendentry{AreaCompV4/ChildArea};
                \addplot coordinates { (1,35.0) (2,83.0) (3,135.0) (4,202.0) (5,265.0) };
                \addlegendentry{AreaCompV4/HeightAdvantageArea};
                \addplot coordinates { (1,35.0) (2,85.0) (3,139.0) (4,192.0) (5,250.0) };
                \addlegendentry{AreaCompV4/HeightFirstArea};
                \addplot coordinates { (1,35.0) (2,78.0) (3,125.0) (4,174.0) (5,232.0) };
                \addlegendentry{AreaCompV4/WidthFirstArea};
                \addplot coordinates { (1,11.0) (2,29.0) (3,45.0) (4,63.0) (5,80.0) };
                \addlegendentry{RePair};
                \addplot coordinates { (1,4.0) (2,9.0) (3,15.0) (4,22.0) (5,29.0) };
                \addlegendentry{Sequitur};
            \end{axis}
        \end{tikzpicture}
        \label{resultsxmlruntime}
    }
    \quad
    \subfloat[Größe der erzeugten Grammatik]{
        \begin{tikzpicture}
            \begin{axis}[sizeplot, title={XML Grammatikgröße}]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, MIN(size / (1.0 * inputsize)) AS y, MULTIPLOT 
                %% FROM xml GROUP BY MULTIPLOT, datasetsize            
                \addplot coordinates { (1,0.150608) (2,0.153637) (3,0.157878) (4,0.157854) (5,0.166147) };
                
                \addplot coordinates { (1,0.086619) (2,0.0805638) (3,0.078124) (4,0.0753391) (5,0.0757765) };
                
                \addplot coordinates { (1,0.088598) (2,0.0824666) (3,0.0799382) (4,0.0771623) (5,0.0775188) };
                
                \addplot coordinates { (1,0.29432) (2,0.29514) (3,0.298642) (4,0.30164) (5,0.366257) };
                
                \addplot coordinates { (1,0.266995) (2,0.277118) (3,0.258805) (4,0.280782) (5,0.304951) };
                
                \addplot coordinates { (1,0.0779639) (2,0.0725272) (3,0.0702591) (4,0.0670736) (5,0.0680445) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsxmlsize}
    }
    \quad
    \subfloat[Tiefe der erzeugten Grammatik]{
        \begin{tikzpicture}
            \begin{axis}[depthplot, title={XML Grammatiktiefe}, ymode=log]
                
                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(depth) AS y, MULTIPLOT 
                %% FROM xml GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,17.0) (2,16.0) (3,17.0) (4,17.0) (5,16.0) };
                
                \addplot coordinates { (1,28.0) (2,33.0) (3,36.0) (4,36.0) (5,36.0) };
                
                \addplot coordinates { (1,26.0) (2,31.0) (3,34.0) (4,33.0) (5,33.0) };
                
                \addplot coordinates { (1,7.0) (2,8.0) (3,7.0) (4,7.0) (5,7.0) };
                
                \addplot coordinates { (1,85.0) (2,116.0) (3,180.0) (4,155.0) (5,243.0) };
                
                \addplot coordinates { (1,19.0) (2,19.0) (3,19.0) (4,19.0) (5,19.0) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsxmldepth}
    }
    \ 
    \subfloat[Anzahl der Regeln]{
        \begin{tikzpicture}
            \begin{axis}[countplot, title={XML Regelanzahl}, ymode=log]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(numRules) AS y, MULTIPLOT 
                %% FROM xml GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,24439.0) (2,34744.0) (3,43287.0) (4,49694.0) (5,55222.0) };
                
                \addplot coordinates { (1,196226.0) (2,361346.0) (3,523543.0) (4,668901.0) (5,815467.0) };
                
                \addplot coordinates { (1,206883.0) (2,380826.0) (3,552165.0) (4,706238.0) (5,861838.0) };
                
                \addplot coordinates { (1,19209.0) (2,26166.0) (3,31415.0) (4,34564.0) (5,38301.0) };
                
                \addplot coordinates { (1,189468.0) (2,393154.0) (3,546340.0) (4,656049.0) (5,800207.0) };
                
                \addplot coordinates { (1,148736.0) (2,271075.0) (3,387604.0) (4,490670.0) (5,600019.0) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsxmlrulenum}
    }
    \subfloat[Durchschnittslänge der Regeln]{
        \begin{tikzpicture}
            \begin{axis}[lengthplot, title={XML Regellänge}, ymode=log]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(avgLen) AS y, MULTIPLOT 
                %% FROM xml GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,2.57026) (2,2.55804) (3,2.59017) (4,2.59298) (5,2.61899) };
                
                \addplot coordinates { (1,2.19464) (2,2.18694) (3,2.18079) (4,2.18614) (5,2.19015) };
                
                \addplot coordinates { (1,2.18764) (2,2.18324) (3,2.17724) (4,2.1818) (5,2.18434) };
                
                \addplot coordinates { (1,2.94409) (2,2.8991) (3,2.88215) (4,2.9592) (5,2.90167) };
                
                \addplot coordinates { (1,2.0) (2,2.0) (3,2.0) (4,2.0) (5,2.0) };
                
                \addplot coordinates { (1,2.20564) (2,2.1848) (3,2.18534) (4,2.17352) (5,2.16774) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsxmlavglen}
    }
    \caption{Die Ergebnisse für die Kompression des \emph{xml} Datensatzes aus dem Pizza\&Chili Corpus. Siehe \autoref{results} für weitere Erläuterungen.}
    \label{resultsxml}
\end{figure}

% ENGLISH PLOT
\begin{figure}
    \centering

    \subfloat[Laufzeiten]{
        \begin{tikzpicture}
            \begin{axis}[runtimeplot, title={English Laufzeit}]
                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG((comptime + unifytime) / 1000) AS y, MULTIPLOT
                %% FROM english GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,44.0) (2,113.0) (3,162.0) (4,231.0) (5,297.0) };
                \addlegendentry{AreaCompV4/ChildArea};
                \addplot coordinates { (1,47.0) (2,114.0) (3,174.0) (4,244.0) (5,315.0) };
                \addlegendentry{AreaCompV4/HeightAdvantageArea};
                \addplot coordinates { (1,46.0) (2,114.0) (3,177.0) (4,242.0) (5,333.0) };
                \addlegendentry{AreaCompV4/HeightFirstArea};
                \addplot coordinates { (1,37.0) (2,89.0) (3,138.0) (4,192.0) (5,246.0) };
                \addlegendentry{AreaCompV4/WidthFirstArea};
                \addplot coordinates { (1,30.0) (2,77.0) (3,121.0) (4,168.0) (5,209.0) };
                \addlegendentry{RePair};
                \addplot coordinates { (1,5.0) (2,13.0) (3,23.0) (4,34.0) (5,47.0) };
                \addlegendentry{Sequitur};
            \end{axis}
        \end{tikzpicture}
        \label{resultsenglishruntime}
    }
    \quad
    \subfloat[Größe der erzeugten Grammatik]{
        \begin{tikzpicture}
            \begin{axis}[sizeplot, title={English Grammatikgröße}]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, MIN(size / (1.0 * inputsize)) AS y, MULTIPLOT 
                %% FROM english GROUP BY MULTIPLOT, datasetsize       
                \addplot coordinates { (1,0.281303) (2,0.266864) (3,0.29072) (4,0.305588) (5,0.314204) };
                
                \addplot coordinates { (1,0.14763) (2,0.124187) (3,0.134434) (4,0.140658) (5,0.139948) };
                
                \addplot coordinates { (1,0.152299) (2,0.128113) (3,0.138901) (4,0.145343) (5,0.14459) };
                
                \addplot coordinates { (1,0.372798) (2,0.374225) (3,0.382871) (4,0.388644) (5,0.389639) };
                
                \addplot coordinates { (1,0.671124) (2,0.582472) (3,0.5846) (4,0.653665) (5,0.60334) };
                
                \addplot coordinates { (1,0.134138) (2,0.116564) (3,0.12048) (4,0.122204) (5,0.120246) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsenglishsize}
    }
    \quad
    \subfloat[Tiefe der erzeugten Grammatik]{
        \begin{tikzpicture}
            \begin{axis}[depthplot, title={English Grammatiktiefe}, ymode=log]
                
                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(depth) AS y, MULTIPLOT 
                %% FROM english GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,17.0) (2,14.0) (3,14.0) (4,14.0) (5,20.0) };
                
                \addplot coordinates { (1,41.0) (2,45.0) (3,63.0) (4,63.0) (5,64.0) };
                
                \addplot coordinates { (1,41.0) (2,45.0) (3,62.0) (4,63.0) (5,64.0) };
                
                \addplot coordinates { (1,9.0) (2,10.0) (3,10.0) (4,11.0) (5,11.0) };
                
                \addplot coordinates { (1,1679.0) (2,3907.0) (3,2516.0) (4,3216.0) (5,13648.0) };
                
                \addplot coordinates { (1,17.0) (2,20.0) (3,29.0) (4,29.0) (5,29.0) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsenglishdepth}
    }
    \ 
    \subfloat[Anzahl der Regeln]{
        \begin{tikzpicture}
            \begin{axis}[countplot, title={English Regelanzahl}, ymode=log]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(numRules) AS y, MULTIPLOT 
                %% FROM english GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,17499.0) (2,22996.0) (3,29151.0) (4,31880.0) (5,36583.0) };
                
                \addplot coordinates { (1,352197.0) (2,592325.0) (3,959541.0) (4,1.33699e+06) (5,1.62917e+06) };
                
                \addplot coordinates { (1,375102.0) (2,630449.0) (3,1.02432e+06) (4,1.4257e+06) (5,1.73823e+06) };
                
                \addplot coordinates { (1,14226.0) (2,18024.0) (3,22198.0) (4,24030.0) (5,27814.0) };
                
                \addplot coordinates { (1,1.76936e+06) (2,3.96516e+06) (3,4.78321e+06) (4,5.97792e+06) (5,6.9114e+06) };
                
                \addplot coordinates { (1,203426.0) (2,352571.0) (3,510494.0) (4,657091.0) (5,783690.0) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsenglishrulenum}
    }
    \subfloat[Durchschnittslänge der Regeln]{
        \begin{tikzpicture}
            \begin{axis}[lengthplot, title={English Regellänge}, ymode=log]

                %% MULTIPLOT(algo) SELECT SUBSTR(datasetsize, 1, 1) AS x, AVG(avgLen) AS y, MULTIPLOT 
                %% FROM english GROUP BY MULTIPLOT, datasetsize
                \addplot coordinates { (1,52.2857) (2,96.1143) (3,85.5238) (4,85.6127) (5,83.0841) };
                
                \addplot coordinates { (1,3.19531) (2,3.61483) (3,3.21938) (4,2.98099) (5,2.96945) };
                
                \addplot coordinates { (1,3.137) (2,3.53201) (3,3.15797) (4,2.93691) (5,2.92538) };
                
                \addplot coordinates { (1,25.7272) (2,40.1565) (3,32.6568) (4,29.4731) (5,27.2751) };
                
                \addplot coordinates { (1,2.0) (2,2.0) (3,2.0) (4,2.0) (5,2.0) };
                
                \addplot coordinates { (1,3.73509) (2,4.26732) (3,3.948) (4,3.71414) (5,3.77808) };
                
            \end{axis}
        \end{tikzpicture}
        \label{resultsenglishavglen}
    }
    \caption{Die Ergebnisse für die Kompression des \emph{english} Datensatzes aus dem Pizza\&Chili Corpus. Siehe \autoref{results} für weitere Erläuterungen.}
    \label{resultsenglish}
\end{figure}

\section{Fazit}

Wir sehen, dass von den hier vorgestellten Flächenfunktionen \texttt{HeightFirstArea} und\\
\texttt{HeightAdvantageArea} die kleinsten Grammatiken erzeugen. Diese benötigen auch in der Regel etwas mehr Laufzeit als die anderen Flächenfunktionen, allerdings ist der Unterschied hier sehr klein im Vergleich zu dem Unterschied in der Grammatikgröße. Die von diesen beiden Flächenfunktionen erzeugten Grammatiken haben fast identische Eigenschaften.

Allerdings scheint \texttt{HeightAdvantageArea} marginal kleinere Grammatiken zu erzeugen, doch der Unterschied zu \texttt{HeightFirstArea} ist sehr gering. AreaComp scheint in der Praxis eine linear steigende Laufzeit zu besitzen. Trotzdem ist AreaComp langsamer als RePair und insbesondere Sequitur. Letzterer erzeugt die kleinsten Grammatik unter all den betrachteten Algorithmen und hat zudem die beste Laufzeit auf allen betrachteten Datensätzen.

Auf manchen Datensätzen kommt die Größe der von \texttt{HeightFirstArea} und\\
\texttt{HeightAdvantageArea} der von Sequitur erzeugten Grammatiken sehr nahe. So zum Beispiel auf den Datensätzen \emph{english} und \emph{xml}.