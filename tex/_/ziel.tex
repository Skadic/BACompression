\chapter{Ziel der Arbeit}

Das Ziel dieser Arbeit soll die Umsetzung und Evaluierung des AreaComp-Algorithmus sein. Dieser Algorithmus hat Ähnlichkeit mit dem lcpcomp-Algorithmus aus Sektion 3.1 in \cite{dinklage_compression_2017}.
lcpcomp sucht nach den zwei längsten wiederholten Substrings und ersetzt eines der Vorkommen durch eine Referenz auf das jeweils andere Vorkommen.
Hierbei bedient er sich des Suffix-Arrays, des inversen Suffix-Arrays und des LCP-Arrays \cite{manber_suffix_1993} um diese Substrings zu bestimmen, da große Werte im LCP-Array lange wiederholte Substrings bedeuten. Dies ähnelt der LZ77-Faktorisierung \cite{ziv_universal_1977}, allerdings sind bei dem lcpcomp-Algorithmus auch Vorwärtsverweise erlaubt.

Der AreaComp-Algorithmus erzeugt eine Straight Line Grammatik und beginnt mit nur einer Produktionsregel, die ein Startsymbol auf den gesamten String abbildet.
Nun werden Intervalle im LCP-Array gesucht, die eine Kostenfunktion maximieren. 

Das gemeinsame Präfix der Suffixe in solch einem Intervall soll bei jedem Vorkommen durch ein neues Symbol ersetzt werden. Für dieses wird eine Produktionsregel erstellt, die das neue Symbol auf den ursprünglichen Substring abbildet. Die Kostenfunktion soll dabei als Heuristik dazu dienen, zu entscheiden, welche Substrings am günstigsten zu ersetzen sind.

Es könnte dann eine Prioritätswarteschlange genutzt werden um die einzelnen Intervalle nach ihren Kosten geordnet zu speichern und sie in dieser Reihenfolge zu verarbeiten. 
Diese wird zum Beispiel als Heap implementiert. Es wurden bereits zahlreiche Modelle vorgestellt, wie ein Heap umgesetzt werden kann. Zum Beispiel etwa der weit bekannte binäre Heap \cite{williams_algorithm_1964} oder der Pairing Heap \cite{fredman_pairing_1986}. Hier gibt es optional die Möglichkeit, die Nutzung verschiedener Heap-Implementationen \cite{larkin_back--basics_2013} zu erforschen.

Sei $\Sigma$ ein Alphabet und $\Sigma^*$ die Menge aller Strings aus Zeichen aus $\Sigma$, inklusive des leeren Strings $\varepsilon \in \Sigma^*$. Außerdem sei für ein gegebenes LCP-Array $LCP$ und ein Intervall $I = [i..j]$ definiert:
\begin{align*}
    w(I) &= |I| + 1 \text{ die Breite von $I$}\\
    h(I) &= \min_{i \leq x \leq j} LCP[x] \text{ die Höhe von $I$} 
\end{align*}
$w(I)$ beschreibt also die Anzahl der Suffixe, die von $I$ betroffen sind, während $h(I)$ die Länge des längsten gemeinsamen Präfixes aller Suffixe in $SA[i - 1..j]$ beschreibt, wobei $SA$ das entsprechende Suffix-Array ist.

Eine Überlegung wäre zum Beispiel die Kostenfunktion $A$ als 
\begin{equation*}
    A(I) = w(I) \cdot h(I)
\end{equation*}
zu definieren. Damit würde die Anzahl ersetzter Vorkommen und die Länge der ersetzten Vorkommen in Betracht gezogen werden.  

Eine grobe vorläufige Skizze des Algorithmus könnte also folgendermaßen aussehen:\\
\begin{algorithmic}[1]
    \REQUIRE String $T \in \Sigma^*$, Kostenfunktion $A(I)$ über Teilintervalle $I \subset [1..n]$
    \STATE Initialisiere Grammatik $G$ mit Startregel $S \rightarrow T$
    \STATE Initialisiere Priority Queue $Q$
    \STATE Füge Auswahl von Teilintervallen $I$ von $[1..n]$ in $Q$ mit Schlüssel $A(I)$ ein
    \WHILE {$Q$ nicht leer}
        \STATE Extrahiere Intervall $I = [i..j]$ mit größtem $A(I)$ aus $Q$
        \STATE Erzeuge neue Produktionsregel $X \rightarrow P$ die neues Symbol $X \notin \Sigma$ auf den gemeinsamen Präfix $P \in \Sigma^*$ der Suffixe im Intervall $I$ abbildet
        \STATE Füge die Produktionsregel $X \rightarrow P$ in $G$ ein
        \STATE Ersetze alle Vorkommen von $P$ in der Startregel $S \rightarrow T$
    \ENDWHILE
    \STATE Gib $G$ aus
\end{algorithmic}

Hierbei muss natürlich darauf geachtet werden, dass etwa überlappende Vorkommen eines Substrings entsprechend behandelt werden und zum Beispiel das LCP-Array angepasst wird, wie im lcpcomp-Algorithmus \cite{dinklage_compression_2017}, um Mehrfachersetzungen zu vermeiden.

Außerdem stellt sich die Frage, welche Teilintervalle $I \subset [1..n]$ überhaupt in Betracht gezogen werden sollen. Alle Teilintervalle zu betrachten wäre unsinnig, da zum Beispiel Teilintervalle mit $h(I) \leq 1$ (längster gemeinsamer Präfix hat 1 oder 0 Zeichen) nicht zur Kompression beitragen würden.

Der Algorithmus soll dann in Hinsicht der Laufzeit und Größe der erzeugten Grammatik evaluiert werden. 

Weiterführend könnte optional der Speicherplatzverbrauch des Algorithmus und die Kodierung der resultierenden Grammatik erforscht \cite{tabei_succinct_2013} und zudem die Kompressionsrate mit anderen Kompressionsverfahren evaluiert werden. 

\section{Arbeitsschritte und Methoden}

Die Implementierung des AreaComp-Algorithmus soll in der Programmiersprache Java\footnote{\href{https://www.java.com}{Java Website}} geschehen. 

Dabei wird die Bibliothek JSuffixArrays\footnote{\href{https://github.com/carrotsearch/jsuffixarrays}{JSuffixArrays GitHub repository}} benutzt, um Suffix-Arrays und LCP-Arrays zu berechnen. Für Suffix-Arrays nutzt JSuffixArrays standardmäßig den SAIS-Algorithmus \cite{nong_two_2011} und für LCP-Arrays den Algoritmus aus \cite{kasai_linear-time_2001}, die beide das jeweilige Array in linearer Laufzeit berechnen.

Zur Evaluation wird der Algorithmus auf verschiedene Textsammlungen angewandt, wie zum Beispiel dem Pizza\&Chili Corpus\footnote{\href{http://pizzachili.dcc.uchile.cl}{Pizza\&Chili Corpus Website}}. 
Hierbei wird die Größe der erzeugten Grammatik mit anderen Grammatikkompressionsalgorithmen wie Re-Pair \cite{larsson_offline_1999} und Sequitur \cite{nevill-manning_identifying_1997} verglichen.

\section{Zeitplan}

%Die Arbeit soll mit etwa 6 Wochen Literaturrecherche beginnen.
%Während der ersten 2 Wochen soll zumindest das Einleitungskapitel fertig geschrieben werden und während der gesamten Recherche schrittweise an Kapitel 2 gearbeitet werden. Abgesehen von Feinschliffen sollten Kapitel 2 und 3 am Ende dieser Zeit fertig geschrieben sein. 

%Nach etwa 4 Wochen Recherche soll mit zunächst prototypischer Implementierung begonnen werden. 
%Diese setzt sich über den Lauf der Bearbeitungszeit fort, um den Algorithmus bei neuen Ideen kontinuierlich weiterentwickeln zu können. Während dieser Zeit wird die Implementierung und die Weiterentwicklung des Algorithmus dokumentiert. Diese Zeit sollte insgesamt etwa 6 Wochen andauern.

%Ist die Implementierung vollständig, können Vergleiche mit anderen Kompressionsalgorithmen vorgenommen werden. Sind diese abgeschlossen, wird das Fazit geschrieben. Dies soll zusammen etwa 2 Wochen einnehmen.

Dies ist ein vorläufiger ungefährer Zeitplan für den Ablauf der Arbeit:

\begin{center}
    \begin{tabular}{|r|cccccccccccccccc|}\hline
        Woche & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 \\\hline
        Recherche & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & & & & & & & & & & \\
        (Kap. 2 + 3) & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & & & & & & & & & & \\ \hline
        Implementierung & & & & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & & & & & & & & & \\
        (Kap. 4) & & & & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & & & & & & & & & \\ \hline
        Evaluation \& & & & & & & & \cc{blue!50} & \cc{blue!50} & & & & & & & & \\
        Vergleich (Kap. 5) & & & & & & & \cc{blue!50} & \cc{blue!50} & & & & & & & & \\ \hline
        Einleitung \& Fazit & & & & & & & & \cc{blue!50} & & & & & & & & \\
        (Kap. 1 + 6) & & & & & & & & \cc{blue!50} & & & & & & & & \\ \hline
        Überarbeitung & & & & & & & & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & & & & \\ \hline
        Pufferzeit & & & & & & & & & & & & & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} & \cc{blue!50} \\ \hline
    \end{tabular}
\end{center}


